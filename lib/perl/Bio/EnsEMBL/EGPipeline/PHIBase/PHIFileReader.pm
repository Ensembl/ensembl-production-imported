=head1 LICENSE

See the NOTICE file distributed with this work for additional information
regarding copyright ownership.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

     http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.

=cut

=pod 

=head1 NAME

    Bio::EnsEMBL::EGPipeline::PHIBase::PHIFileReader

=head1 SYNOPSIS

    seed_pipeline.pl -url $EHIVE_URL -logic_name inputfile  -input_id "{'inputfile' => $INPUT_ROTHAMSTED_FILE , 'delimiter' => ',' }"
    
=head1 DESCRIPTION

    This is a generic RunnableDB module for creating batches of similar jobs using dataflow mechanism
    (a fan of jobs is created in one branch and the funnel in another).
    Make sure you wire this buliding block properly from outside.

    You can supply as parameter one of 4 sources of ids from which the batches will be generated:

        param('inputlist');  The list is explicitly given in the parameters, can be abbreviated: 'inputlist' => ['a'..'z']

        param('inputfile');  The list is contained in a file whose name is supplied as parameter: 'inputfile' => 'myfile.txt'

        param('inputquery'); The list is generated by an SQL query (against the production database by default) : 'inputquery' => 'SELECT object_id FROM object WHERE x=y'

        param('inputcmd');   The list is generated by running a system command: 'inputcmd' => 'find /tmp/big_directory -type f'

    NB for developpers: fetch_input() method is intentionally missing from JobFactory.pm .
    If JobFactory is subclassed (say, by a Compara RunnableDB) the child class's should use fetch_input()
    to set $self->param('inputlist') to whatever list of ids specific to that particular type of data (slices, members, etc).
    The rest functionality will be taken care for by the parent class code.

=head1 CONTACT

  Please email comments or questions to the public Ensembl
  developers list at <https://lists.ensembl.org/mailman/listinfo/dev>.

  Questions may also be sent to the Ensembl help desk at
  <https://www.ensembl.org/Help/Contact>.

=cut


package Bio::EnsEMBL::EGPipeline::PHIBase::PHIFileReader;

use strict;
use warnings;

use base ('Bio::EnsEMBL::Hive::Process');
use Data::Dumper;
use Scalar::Util qw(looks_like_number);

sub param_defaults {

    return {
        'column_names'      => 0,
        'delimiter'         => ',',

        'inputfile'         => undef,
        'lookup'            => undef,

        'MAX_SUB_TAX_DBAS' => 15,
        'fan_branch_code'   => 2,
        'use_bash_pipefail' => 0           # Boolean. When true, the command will be run with "bash -o pipefail -c $cmd". Useful to capture errors in a command that contains pipes
    };
}

sub fetch_input {
    my $self = shift;
    my $inputfile = $self->param_required('inputfile');

    unless (-e $inputfile) {
        die "File $inputfile does not exist"; # Will cause job to fail and leave a message in log_message
    }
}


=head2 run

    Description : Implements run() interface method of Bio::EnsEMBL::Hive::Process that is used to perform the main bulk of the job (minus input and output).

    param('column_names'):  Controls the column names that come out of the parser: 0 = "no names", 1 = "parse names from data", arrayref = "take names from this array"

    param('delimiter'): If you set it your lines in file/cmd mode will be split into columns that you can use individually when constructing the input_id_template hash.

    param('randomize'): Shuffles the rows before creating jobs - can sometimes lead to better overall performance of the pipeline. Doesn't make any sence for minibatches (step>1).

    param('step'):      The requested size of the minibatch (1 by default). The real size of a range may be smaller than the requested size.

    param('contiguous'): Whether the key_column range of each minibatch should be contiguous (0 by default).

    param('key_column'): If every line of your input is a list (it happens, for example, when your SQL returns multiple columns or you have set the 'delimiter' in file/cmd mode)
                         this is the way to say which column is undergoing 'ranging'



=cut

sub run {
    my $self = shift @_;

    my $delimiter       = $self->param('delimiter');
    my $inputfile       = $self->param_required('inputfile');
  
    my ($rows) = $inputfile    ? $self->_get_rows_from_open(  $inputfile  , '<', $delimiter )
            : die "range of values should be defined by setting 'inputfile' ";

    my $output_PHI_entries =  $self->_substitute_rows($rows);
    $self->param('PHI_entries', $output_PHI_entries);
}

=head2 write_output

    Description : Implements write_output() interface method of Bio::EnsEMBL::Hive::Process that is used to deal with job's output after the execution.
                  Here we rely on the dataflow mechanism to create jobs.

    param('fan_branch_code'): defines the branch where the fan of jobs is created (2 by default).

=cut

sub write_output {  # nothing to write out, but some dataflow to perform:
    my $self = shift @_;

    my $PHI_entries  = $self->param('PHI_entries');
    my $fan_branch_code     = $self->param('fan_branch_code');

    # "fan out" into fan_branch_code:
    $self->dataflow_output_id($PHI_entries, $fan_branch_code);
}


=head2 _get_rows_from_open
    
    Description: a private method that loads rows from a given file into an array. It also performs validation on each line.

=cut

sub _get_rows_from_open {
    my ($self, $input_file_or_command, $open_mode, $delimiter) = @_;


    $self->say_with_header(qq{input_file_or_command = "$input_file_or_command" [$open_mode]\n});
    my @rows = ();
    open(my $fh, $open_mode, $input_file_or_command) or die "Could not open '$input_file_or_command' because: $!";

    LINE: while(my $line = <$fh>) {
        chomp $line;
        $line =~ s/\r//g; 
        my @fields = split( /$delimiter/, $line, -1 );
        
        #validation of the line
        if ( (scalar(@fields) == 15) || (scalar(@fields) == 14 && ($fields[13] eq '' or $fields[14] eq '' )  ) ){ # all fields are complete or all except one of the two publication identifiers
            
            # accept only utf-8 coding entries, discard otherwise
            foreach my $annotation_field (1,2,3,4,6,8) { 
                if ($fields[$annotation_field] =~ /[^\x00-\x7f]/ ) {
                    $self->warning( "The entry " . $fields[1] . " contains one or more non utf-8 coding characters :$fields[$annotation_field]. This entry will be skipped." );
                    next LINE;
                }
            }

            my $annotn_tax_id = $fields[6];

            if ( $annotn_tax_id eq '' || $annotn_tax_id eq 'no data found' || !looks_like_number($annotn_tax_id) || !looks_like_number($fields[0]) || $fields[0] < 0) {
                $self->warning( "The entry '" . $fields[1] . "' has either an empty or non valid Tax id : '$annotn_tax_id', or a non valid phibase_number '" . $fields[0] . "'\n");
                next LINE;
            }

      } else {
        $self->warning( "The entry " . $fields[1] . " contains an abnormal number of delimiters. This entry will be skipped." );
        next LINE;
      }

      push(@rows,[@fields ]); 
      
    }
    close $fh
        or die "Could not read from $open_mode '$input_file_or_command'. Received the error ".($! || $?);

    my $column_names_from_data =  1;
    return (\@rows, $column_names_from_data);
}

=head2 _substitute_rows

    Description: a private method that goes through a list and transforms every row into a hash

=cut

sub _substitute_rows {
    my ($self, $rows) = @_;
    my @hashes = ();
    my $line_fields = [  'id_number', # 0
                         'phi_entry', # 1
                         'uniprot_acc', # 2
                         'gene_name', # 3
                         'locus', # 4
                         'origin', # 5
                         'species_tax_id', # 6
                         'subtaxon_id', # 7
                         'pathogen_name', # 8
                         'host_tax_id', # 9
                         'host_name', # 10
                         'phenotype', # 11
                         'experiment_condition', # 12
                         'litterature_id', # 13
                         'DOI', # 14

                      ];

    foreach my $row (@$rows) {
        my $job_param_hash = {};
        for (my $i = 0 ; $i < scalar(@$line_fields); $i++)  {
            $job_param_hash->{ @$line_fields[ $i ] } = @$row[ $i ];
        }
        push @hashes, $job_param_hash;
    }

    return \@hashes;
}


1;
